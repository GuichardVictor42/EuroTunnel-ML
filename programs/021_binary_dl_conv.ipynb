{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3f025e",
   "metadata": {},
   "source": [
    "On met en place un modèle d'apprentissage supervisé pour classifier les blochets en (non)-exploitables. Une classification \"à la main\" a déjà été effectuée, et montre que la proportion de blochets non exploitables se situe autour de 18%: il s'agit donc d'un problème de classification non-équilibrée (imbalanced classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8091f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy.random as rd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.engine.topology import Layer, InputSpec\n",
    "# from keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import imblearn\n",
    "# import metrics\n",
    "import os\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f13ab8",
   "metadata": {},
   "source": [
    "On reprend la même procédure d'import des données que pour la classification à l'aide de la SOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae87564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonctions et variables utiles\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, encoding='ISO-8859-1') as f:\n",
    "        lines = f.readlines()\n",
    "        return lines\n",
    "        \n",
    "def read_number_line(some_line):\n",
    "    return [float(s) for s in some_line.split()]\n",
    "\n",
    "# my_dpi = np.sqrt(1920**2 + 1080**2)/17.3 #dpi de l'écran\n",
    "# tnorm = 60. #normalisation du temps\n",
    "# vnorm = 1.05 #normalisation de la vitesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831e199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dossiers où récupérer les données\n",
    "\n",
    "#training\n",
    "folder = \"C:/Users/victo/stage_navier_jupyter/data_eurotunnel/Data/training/\"\n",
    "pk_folder = \"1775_20190128/\" #le PK qu'on va traiter\n",
    "\n",
    "done = [\"1775_20190128/\", \"1780_20190128/\", \"1785_20190128/\", \"1795_20190128/\", \"1800_20190128/\", \"1805_20190128/\",\n",
    "        \"1810_20190128/\", \"1815_20190128/\", \"1820_20190128/\", \"1825_20190128/\", \"1830_20190128/\", \"1835_20190128/\",\n",
    "        \"1840_20190128/\", \"3020_20190218/\", \"3025_20190218/\", \"3030_20190218/\", \"3035_20190218/\", \"3040_20190218/\",\n",
    "        \"3045_20190218/\", \"3050_20190218/\", \"3055_20190218/\", \"3060_20190218/\", \"3065_20190218/\", \"3070_20190218/\",\n",
    "        \"3075_20190218/\", \"3080_20190218/\", \"4230_20190225/\", \"4235_20190225/\", \"4240_20190225/\", \"4255_20190225/\",\n",
    "        \"4260_20190225/\"]\n",
    "failed = [\"1790_20190128/\", \"3015_20190218\"]\n",
    "\n",
    "# #validation\n",
    "# folder = \"C:/Users/victo/stage_navier_jupyter/data_eurotunnel/Data/validation/\"\n",
    "# pk_folder = \"4250_20190225/\" #le PK qu'on va traiter\n",
    "\n",
    "done_val = [\"4245_20190225/\", \"4250_20190225/\"]\n",
    "\n",
    "os.chdir(folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd5ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = folder + pk_folder #pour accéder aux fichiers .blochet du PK pk_folder\n",
    "\n",
    "mySeries = [] #series pandas\n",
    "namesofMySeries = [] #nom correspondant a chaque blochet\n",
    "\n",
    "# os.chdir(path) #current directory: C:/Users/victo/stage_navier_jupyter/data_eurotunnel/Data/training/1775-20190128/\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, encoding='ISO-8859-1') as f:\n",
    "        lines = f.readlines()\n",
    "        return lines\n",
    "    \n",
    "y_true = []\n",
    "\n",
    "for pk_folder_loop in os.listdir(folder):\n",
    "    if (pk_folder_loop + \"/\") in done:\n",
    "        path = folder + pk_folder_loop\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\".blochet\"):\n",
    "                file_path = f\"{path}/{file}\"\n",
    "                lines = read_text_file(file_path)\n",
    "                \n",
    "                y_true.append(int(lines[-1][-1]))\n",
    "\n",
    "                times = []\n",
    "                speeds = []\n",
    "                freqs = []\n",
    "                frfs_real = []\n",
    "                frfs_imag = []\n",
    "\n",
    "                lines_to_read = lines[15:len(lines)-1] #valeurs commencent ligne 16 et saut de ligne à la fin\n",
    "                \n",
    "                for i in range(len(lines_to_read)):\n",
    "                    read_line = read_number_line(lines_to_read[i])\n",
    "                    times.append(read_line[0])\n",
    "                    speeds.append(read_line[1])\n",
    "                    freqs.append(read_line[2])\n",
    "                    frfs_real.append(read_line[3])\n",
    "                    frfs_imag.append(read_line[4])\n",
    "\n",
    "                dict = {\"Temps\":times, \"Vitesses\":speeds, \"Fréquences\":freqs, \"FRF réel\":frfs_real, \"FRF imag\":frfs_imag}\n",
    "                df = pd.DataFrame(dict)\n",
    "\n",
    "                df = df.loc[:, [\"Temps\", \"Vitesses\"]]\n",
    "                df.set_index(\"Temps\", inplace=True)\n",
    "\n",
    "                mySeries.append(df)\n",
    "                namesofMySeries.append(pk_folder_loop + \"_\" + file[:-8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b61c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_series = {namesofMySeries[i]: mySeries[i] for i in range(len(mySeries))}\n",
    "# print(dict_series.keys())\n",
    "# print(dict_series.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8332cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4850"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mySeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a0c30ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vitesses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temps</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>0.001956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.097656</th>\n",
       "      <td>0.002443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.195312</th>\n",
       "      <td>0.001975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.292969</th>\n",
       "      <td>0.003927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.390625</th>\n",
       "      <td>0.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.472660</th>\n",
       "      <td>-0.000771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.570310</th>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.667970</th>\n",
       "      <td>0.000449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.765630</th>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.863280</th>\n",
       "      <td>-0.002553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Vitesses\n",
       "Temps              \n",
       "0.000000   0.001956\n",
       "0.097656   0.002443\n",
       "0.195312   0.001975\n",
       "0.292969   0.003927\n",
       "0.390625   0.002536\n",
       "...             ...\n",
       "59.472660 -0.000771\n",
       "59.570310  0.000244\n",
       "59.667970  0.000449\n",
       "59.765630  0.000154\n",
       "59.863280 -0.002553\n",
       "\n",
       "[614 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySeries[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfbe3915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs inscrites: {0, 1}\n",
      "Bonne longueur de liste: True\n",
      "Pourcentage de blochets inexploitables: 18.186%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true_values = {x for x in y_true}\n",
    "print(\"Valeurs inscrites: \" + str(y_true_values) + \"\\n\" + \n",
    "      \"Bonne longueur de liste: \" + str(len(mySeries)==len(y_true)) + \"\\n\" +\n",
    "      \"Pourcentage de blochets inexploitables: \" + str(round(100*(1 - np.sum(y_true)/len(y_true)), 3)) + \"%\" + \"\\n\")\n",
    "\n",
    "#valeurs en float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95bf6820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{614}\n"
     ]
    }
   ],
   "source": [
    "series_lengths = {len(series) for series in mySeries}\n",
    "print(series_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09921625",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mySeries)):\n",
    "    scaler = MinMaxScaler()\n",
    "    mySeries[i] = MinMaxScaler().fit_transform(mySeries[i])\n",
    "    mySeries[i]= mySeries[i].reshape(len(mySeries[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898fe584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 1.0\tmin: 0.0\n",
      "[0.40812886 0.40739371 0.40760733 0.40815812 0.40736352]\n"
     ]
    }
   ],
   "source": [
    "print(\"max: \"+str(max(mySeries[0]))+\"\\tmin: \"+str(min(mySeries[0])))\n",
    "print(mySeries[0][-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe83605",
   "metadata": {},
   "source": [
    "On vectorise les données obtenues ($x$ représente les échantillons de chaque blochet et $y$ les valeurs d'exploitabilité) pour pouvoir les passer au modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2488a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4850, 614)\n",
      "(4850, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(mySeries, dtype=\"float32\")\n",
    "print(x.shape)\n",
    "y = np.array(y_true, dtype=\"uint8\")\n",
    "y = np.reshape(y, (y.shape[0], 1))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf6bb12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43668875 0.4370555  0.43670303 0.43817562 0.437126   0.4376144\n",
      " 0.43649477 0.4357442  0.43716148 0.43652102 0.43789363 0.43794847\n",
      " 0.4391713  0.43937728 0.44004813 0.43763283 0.44081575 0.44053468\n",
      " 0.43544745 0.4379443  0.43340215 0.43301603 0.42847112 0.43067583\n",
      " 0.427721   0.42901942 0.42784354 0.42715794 0.42858723 0.42816055\n",
      " 0.4274519  0.42756388 0.42805827 0.42524487 0.4276491  0.4264023\n",
      " 0.42641243 0.42678335 0.4290839  0.42943916 0.4304533  0.43138126\n",
      " 0.43217975 0.4310956  0.43193695 0.43094677 0.4307841  0.42897335\n",
      " 0.43063483 0.42795458 0.43136975 0.4291945  0.43331736 0.4311168\n",
      " 0.43790606 0.43150198 0.44112584 0.42963222 0.4436969  0.42015857\n",
      " 0.4679904  0.6194971  0.39961517 0.41887534 0.40219128 0.4148801\n",
      " 0.4107084  0.4205668  0.41834223 0.42405012 0.4219394  0.42503154\n",
      " 0.42237988 0.42453852 0.424398   0.42530525 0.42664006 0.4299704\n",
      " 0.4297875  0.43255666 0.43351457 0.43562576 0.43587273 0.43740708\n",
      " 0.43775493 0.43788072 0.43796825 0.4365975  0.43639848 0.43715042\n",
      " 0.43694124 0.43750796 0.43992096 0.44089085 0.4421962  0.442844\n",
      " 0.44314674 0.44213536 0.44100422 0.4415912  0.44046697 0.44040245\n",
      " 0.43982375 0.4394648  0.43912384 0.4403103  0.44084984 0.44162023\n",
      " 0.4427159  0.44286105 0.44227174 0.4412977  0.44004077 0.43897086\n",
      " 0.43762547 0.437942   0.4376881  0.437807   0.43946895 0.4397256\n",
      " 0.43970394 0.44037113 0.439897   0.43899253 0.4381839  0.43768904\n",
      " 0.4366892  0.43542305 0.4362819  0.434848   0.4365565  0.43521616\n",
      " 0.43850228 0.43599898 0.44042134 0.43535808 0.441218   0.4333722\n",
      " 0.44188747 0.42933732 0.44215333 0.4255103  0.44437835 0.42054835\n",
      " 0.45121694 0.41767737 0.4607726  0.40994307 0.46669933 0.45058244\n",
      " 1.         0.8601362  0.726336   0.58449143 0.01066608 0.37150198\n",
      " 0.3406491  0.5873025  0.68957806 0.28036663 0.22019756 0.\n",
      " 0.0726672  0.4452395  0.3150392  0.56731385 0.20435803 0.10185121\n",
      " 0.24849689 0.19890495 0.51408976 0.5027772  0.36752653 0.396987\n",
      " 0.14060837 0.4423372  0.44311634 0.50751793 0.5794406  0.30043963\n",
      " 0.3749973  0.37425777 0.4320959  0.6761336  0.47529018 0.51138186\n",
      " 0.3368847  0.31077123 0.5169566  0.48571992 0.6376768  0.50919837\n",
      " 0.30120397 0.37215623 0.28099695 0.52231705 0.57224125 0.5402023\n",
      " 0.5295164  0.30126342 0.38771838 0.4915181  0.57255864 0.7426777\n",
      " 0.5498561  0.5013654  0.412134   0.40391636 0.6316791  0.6575618\n",
      " 0.71851826 0.60725564 0.43495536 0.49790147 0.4687511  0.64541477\n",
      " 0.70426744 0.590162   0.5458333  0.3758529  0.4212782  0.5094485\n",
      " 0.5327629  0.60786706 0.44720417 0.36623365 0.3278027  0.31206545\n",
      " 0.47089684 0.4317457  0.41868368 0.345623   0.2205546  0.28962514\n",
      " 0.31002614 0.40627635 0.42202094 0.3070681  0.3018933  0.23308125\n",
      " 0.30137953 0.4015098  0.3962461  0.42181638 0.3166178  0.29037017\n",
      " 0.340433   0.3676362  0.4764089  0.44634208 0.40901694 0.36284477\n",
      " 0.31244424 0.4018213  0.44691253 0.47546667 0.45909268 0.36717728\n",
      " 0.37178394 0.35418713 0.41548553 0.48279226 0.4535244  0.41860026\n",
      " 0.34848294 0.32983786 0.39555496 0.4109489  0.49522123 0.42350274\n",
      " 0.3785009  0.34709558 0.36895627 0.42412156 0.48304752 0.45248955\n",
      " 0.5093781  0.32448202 0.5909895  0.2610931  0.28297266 0.52650535\n",
      " 0.4801839  0.52795815 0.44527268 0.49869767 0.5293755  0.58008105\n",
      " 0.58450335 0.5432641  0.48321155 0.49953532 0.4905731  0.5476063\n",
      " 0.5578531  0.5285991  0.49030817 0.44562054 0.46591374 0.48762056\n",
      " 0.5041991  0.5164244  0.45544255 0.4290678  0.41526115 0.42549276\n",
      " 0.4705333  0.46029112 0.44495246 0.40576446 0.3769168  0.40120158\n",
      " 0.41911954 0.45511726 0.44621953 0.40269718 0.38994938 0.37428817\n",
      " 0.40985185 0.4450432  0.45121232 0.4413567  0.39672622 0.38578412\n",
      " 0.40082788 0.42588672 0.46364358 0.44549292 0.4230157  0.38962868\n",
      " 0.3760976  0.41203538 0.42908347 0.4468973  0.43096197 0.38942364\n",
      " 0.3826938  0.37871423 0.4059778  0.4317282  0.4223338  0.40366247\n",
      " 0.37389746 0.36948523 0.38699776 0.40121216 0.42491636 0.4100306\n",
      " 0.39155743 0.38040707 0.386214   0.41626605 0.43296996 0.4361478\n",
      " 0.426036   0.40620124 0.4170254  0.4326041  0.4558913  0.46556172\n",
      " 0.45187396 0.44660103 0.44016838 0.45053315 0.473073   0.4786436\n",
      " 0.481322   0.46165127 0.44833535 0.453523   0.46480885 0.48575863\n",
      " 0.485989   0.4678236  0.45059076 0.44036558 0.45551765 0.47023797\n",
      " 0.47549385 0.47073883 0.44643193 0.43218344 0.43097994 0.4427915\n",
      " 0.45979166 0.45712155 0.4485307  0.42948708 0.41957203 0.4303109\n",
      " 0.44415903 0.45747817 0.45271623 0.43690714 0.42676815 0.42226377\n",
      " 0.43635792 0.4491071  0.4523103  0.44607347 0.4289904  0.4257093\n",
      " 0.42924473 0.43945652 0.4482561  0.44191006 0.43146282 0.4202309\n",
      " 0.41925225 0.43032795 0.4373504  0.44086415 0.43350857 0.4215496\n",
      " 0.42006135 0.42214352 0.43349984 0.4370629  0.43140337 0.42308483\n",
      " 0.4148216  0.4189228  0.42733118 0.43542764 0.43926805 0.43102923\n",
      " 0.4247869  0.4252928  0.43130893 0.44335914 0.44523075 0.44271547\n",
      " 0.4347563  0.4270036  0.43298146 0.44083005 0.4483169  0.44875142\n",
      " 0.44069457 0.4347692  0.43223736 0.43916026 0.4484344  0.45067\n",
      " 0.44720232 0.43736607 0.43234977 0.4347342  0.44091895 0.44821048\n",
      " 0.44626376 0.43890914 0.43238434 0.42913276 0.43382788 0.4410231\n",
      " 0.44298548 0.43949798 0.43070117 0.42600882 0.42777812 0.4344642\n",
      " 0.44016886 0.4380314  0.4318001  0.42565447 0.4229558  0.42935485\n",
      " 0.4332114  0.43751442 0.43279025 0.42739615 0.42229557 0.42240843\n",
      " 0.42864943 0.43201986 0.43346435 0.42913    0.42470717 0.4246657\n",
      " 0.42803478 0.4361128  0.4383811  0.43551427 0.4306316  0.428989\n",
      " 0.43259674 0.43726838 0.43842348 0.43877274 0.43668276 0.4345439\n",
      " 0.43410942 0.4381673  0.4466545  0.4458242  0.442322   0.44117284\n",
      " 0.44203678 0.44345084 0.4471056  0.45343086 0.45170626 0.44603938\n",
      " 0.44666234 0.448398   0.45091006 0.45459843 0.45752794 0.45313966\n",
      " 0.447588   0.4463209  0.44968444 0.45157817 0.45185876 0.45135283\n",
      " 0.4458196  0.44275093 0.44128942 0.44666648 0.44954574 0.44700053\n",
      " 0.44559568 0.442457   0.43682465 0.43786737 0.4426482  0.4430191\n",
      " 0.43830416 0.43610036 0.43615702 0.43353024 0.43428037 0.44124702\n",
      " 0.4412659  0.4337795  0.4330363  0.43426377 0.4330151  0.4314863\n",
      " 0.43608606 0.43400943 0.42868537 0.42409575 0.43126422 0.43123704\n",
      " 0.43198717 0.43063712 0.43176967 0.42966172 0.42569274 0.42836836\n",
      " 0.43448907 0.43156788 0.4263387  0.42572775 0.42801496 0.42863283\n",
      " 0.42525226 0.4329225  0.4337514  0.43080714 0.42518038 0.43005198\n",
      " 0.43095598 0.43576032 0.42966217 0.43061227 0.43222722 0.42921156\n",
      " 0.42614982 0.42776152 0.43326622 0.43383387 0.4311283  0.4303252\n",
      " 0.43032935 0.43404445 0.4367514  0.43391037 0.4350761  0.4333533\n",
      " 0.4347296  0.43182313 0.43478534 0.43536913 0.43702602 0.43739092\n",
      " 0.43465632 0.43508667 0.437478   0.43912292 0.4397657  0.4384152\n",
      " 0.43511802 0.43421632 0.4339841  0.43771854 0.4379208  0.4371836\n",
      " 0.43675187 0.43466416 0.435664   0.43885568 0.44066232 0.4399546\n",
      " 0.43847188 0.43616992 0.4339841  0.434631   0.4353963  0.43555158\n",
      " 0.43532857 0.43328604]\n"
     ]
    }
   ],
   "source": [
    "print(x[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4108649f",
   "metadata": {},
   "source": [
    "On sépare ensuite les 4850 données en un ensemble d'entraînement et un ensemble de test selon une proportion 80/20 à l'aide d'une fonction pré-implémentée de scikit-learn. Le paramètre stratify = y indique que l'on veut une répartition la plus homogène possible des blochets inexploitables parmi les blochets exploitables, ce qui est essentiel dans un problème de classification non équilibrée comme celui-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a41aef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_to_split, x_test, y_train_to_split, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3ab28",
   "metadata": {},
   "source": [
    "L'ensemble d'entraînement est ensuite lui-même séparé en un ensemble de training pur et un ensemble de validation, là aussi selon un principe 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b3e496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 3104\n",
      "Number of validation samples: 776\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(x_train_to_split) * 0.2)\n",
    "x_train = x_train_to_split[:-num_val_samples]\n",
    "y_train = y_train_to_split[:-num_val_samples]\n",
    "x_val = x_train_to_split[-num_val_samples:]\n",
    "y_val = y_train_to_split[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(x_train))\n",
    "print(\"Number of validation samples:\", len(x_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce614b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3104, 614)\n",
      "(3104, 1)\n",
      "(776, 614)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6095302",
   "metadata": {},
   "source": [
    "On analyse ensuite la répartition des classes dans l'ensemble de training pour affecter des poids différents aux deux classes (la classe \"exploitable\" codée par un \"1\" aura un poids plus faible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "addee1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 2527 (81.41% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(y_train[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(y_train)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd26739",
   "metadata": {},
   "source": [
    "On reshape les données pour les passer dans un CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32b26acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn = x_train.reshape(1, x_train.shape[0], x_train.shape[1])\n",
    "y_train_cnn = y_train.reshape(1, y_train.shape[0], y_train.shape[1])\n",
    "x_val_cnn = x_val.reshape(1, x_val.shape[0], x_val.shape[1])\n",
    "y_val_cnn = y_val.reshape(1, y_val.shape[0], y_val.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc01e5b",
   "metadata": {},
   "source": [
    "Les données étant déjà normalisées entre 0 et 1, on peut passer à la confection du modèle. On utilisera un modèle de CNN moyenneemnt élaboré avec 3 filtres convolutionnels, 3 MaxPool, un Dropout et deux Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de0327c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 3098, 16)          68784     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1548, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 1542, 32)          3616      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 770, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 764, 64)           14400     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 381, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 24384)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24384)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               12485120  \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 12,572,433\n",
      "Trainable params: 12,572,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## CREATION DU MODELE\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(16, kernel_size = 7, activation='relu', input_shape=x_train_cnn.shape[1:]))\n",
    "model.add(layers.MaxPooling1D(pool_size=4, strides=2))\n",
    "model.add(layers.Conv1D(32, kernel_size = 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=4, strides=2))\n",
    "model.add(layers.Conv1D(64, kernel_size = 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=4, strides=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.42))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Ajout de layers convolutionnels, on part sur cette première approche"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218dc85",
   "metadata": {},
   "source": [
    "On définit ensuite les métriques utilisées pour calculer l'erreur du modèle. Dans les faits, seul le taux de faux positifs ou $FPR$ défini par $\\frac{f_p}{f_p+t_n}$ nous intéresse ici. Comme celle-ci n'est pas déjà implémentée, on mesurera à la place la spécificité définie par $1 - FPR$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ef04c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metrix = [\n",
    "    metrics.FalseNegatives(name=\"fn\"),\n",
    "    metrics.FalsePositives(name=\"fp\"),\n",
    "    metrics.TrueNegatives(name=\"tn\"),\n",
    "    metrics.TruePositives(name=\"tp\"),\n",
    "#     keras.metrics.Precision(name=\"precision\"),\n",
    "#     keras.metrics.Recall(name=\"recall\"),\n",
    "    metrics.SpecificityAtSensitivity(0.5, name=\"spec\")\n",
    "#     metrics.AUC(name=\"auc\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d60b62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e08633c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\input_spec.py:229 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_5 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, 614)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5680/297674946.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mweight_for_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mweight_for_1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m historique = model.fit(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\victo\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\input_spec.py:229 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_5 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: (None, 614)\n"
     ]
    }
   ],
   "source": [
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "historique = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=0,\n",
    "    validation_data=(x_val, y_val),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298d9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
